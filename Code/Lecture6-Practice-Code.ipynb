{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to use today is **Boston Dataset**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "from sklearn import feature_selection\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.9</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim  zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "\n",
       "   black  lstat  medv  \n",
       "0  396.9   4.98  24.0  \n",
       "1  396.9   9.14  21.6  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/ga-students/SF-DAT-20/master/Data/Boston.csv\"\n",
    "BostonData = pd.read_csv(url)\n",
    "del BostonData['Unnamed: 0']\n",
    "BostonData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston data frame has 506 rows and 14 columns.\n",
    "Usage\n",
    "\n",
    "Boston\n",
    "\n",
    "Format\n",
    "\n",
    "This data frame contains the following columns:\n",
    "\n",
    "crim\n",
    "\n",
    "    per capita crime rate by town \n",
    "    \n",
    "zn\n",
    "\n",
    "    proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "    \n",
    "indus\n",
    "\n",
    "    proportion of non-retail business acres per town \n",
    "    \n",
    "chas\n",
    "\n",
    "    Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "    \n",
    "nox\n",
    "\n",
    "    nitrogen oxides concentration (parts per 10 million) \n",
    "    \n",
    "rm\n",
    "\n",
    "    average number of rooms per dwelling \n",
    "    \n",
    "age\n",
    "\n",
    "    proportion of owner-occupied units built prior to 1940 \n",
    "    \n",
    "dis\n",
    "\n",
    "    weighted mean of distances to five Boston employment centres \n",
    "    \n",
    "rad\n",
    "\n",
    "    index of accessibility to radial highways \n",
    "    \n",
    "tax\n",
    "\n",
    "    full-value property-tax rate per 10,000 dollars\n",
    "    \n",
    "ptratio\n",
    "\n",
    "    pupil-teacher ratio by town \n",
    "    \n",
    "black\n",
    "\n",
    "    1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "    \n",
    "lstat\n",
    "\n",
    "    lower status of the population (percent) \n",
    "    \n",
    "medv\n",
    "\n",
    "    median value of owner-occupied homes in 1000 dollars\n",
    "\n",
    "Source\n",
    "\n",
    "Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. J. Environ. Economics and Management 5, 81â€“102.\n",
    "\n",
    "Belsley D.A., Kuh, E. and Welsch, R.E. (1980) Regression Diagnostics. Identifying Influential Data and Sources of Collinearity. New York: Wiley.\n",
    "[Package MASS version 7.2-29 Index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our goal is to predict the median value of properties (medv) based on other variables in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's draw a scatter-plot of medv and lstat. Intuitively, does it like a pure linear association or it seems like there is some sort of non-linearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1154b4f50>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZrCwMwzDxIz/D1UKTBNB5x/OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114e3e490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(BostonData.medv,BostonData.lstat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It does not look strictly linear.  It looks like there is quadratic or something higher. Diminishing returns to scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's first define few non-linear terms. Start from a pure linear function and go up to polynomial degree 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BostonData['lstat_2'] = BostonData['lstat']**2\n",
    "BostonData['lstat_3'] = BostonData['lstat']**3\n",
    "BostonData['lstat_4'] = BostonData['lstat']**4\n",
    "BostonData['lstat_5'] = BostonData['lstat']**5\n",
    "X1 = BostonData[['lstat']]\n",
    "X2 = BostonData[['lstat','lstat_2']]\n",
    "X3 = BostonData[['lstat','lstat_2','lstat_3']]\n",
    "X4 = BostonData[['lstat','lstat_2','lstat_3','lstat_4']]\n",
    "X5 = BostonData[['lstat','lstat_2','lstat_3','lstat_4','lstat_5']]\n",
    "y = BostonData['medv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now divide your dataset into 25% test set and 75% training set and use Validation and MSE of test set to decide which degree of polynomial fits the best. Run this procedure a few times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115618a10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEPCAYAAAC9RFRvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuVLOKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103d38150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "MSE_test = np.zeros(5)\n",
    "MSE_train = np.zeros(5)\n",
    "i = 0\n",
    "for X in [X1,X2,X3,X4,X5]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.25)\n",
    "    #We train based on Training Data BUT will Test on Test Sample\n",
    "    Model_train = lm.fit(X_train,y_train)\n",
    "    y_Hat_train = lm.predict(X_train)\n",
    "    y_Hat_test  = lm.predict(X_test)\n",
    "    MSE_test[i] = (metrics.mean_squared_error(lm.predict(X_test),y_test))\n",
    "    MSE_train[i] = (metrics.mean_squared_error(lm.predict(X_train),y_train))\n",
    "    i += 1\n",
    "\n",
    "index = np.array(range(5)) + 1\n",
    "MSE_Test_df = pd.DataFrame({'MSE_test':MSE_test,'index':index})\n",
    "MSE_Test_df.plot(x = 'index',y= 'MSE_test')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The result will keep changing because of variance so we can\n",
    "not use validation, we will try cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, on the same data set, use 10 fold cross-validation to decide on the degree of polynomial. Justify what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.830533044001982, 30.779870521376655, 29.45725396663811, 28.321686828827229, 27.760486383232422]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115634850>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEPCAYAAAC9RFRvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1156f8510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = cross_validation.KFold(len(BostonData), n_folds = 10, shuffle = True)\n",
    "MSE_CV = []\n",
    "\n",
    "for i in [X1,X2,X3,X4,X5]:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.LinearRegression().fit(i.iloc[train_index], y.iloc[train_index])\n",
    "        scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(i.iloc[test_index])))\n",
    "    MSE_CV.append(np.mean(scores))\n",
    "        \n",
    "        \n",
    "print(MSE_CV)\n",
    "index = np.array(range(5)) + 1\n",
    "MSE_CV_df = pd.DataFrame({'MSE_CV':MSE_CV,'index':index})\n",
    "MSE_CV_df.plot(x = 'index',y= 'MSE_CV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: He recommends X2, because the improvement does not outweigh the confidence interval issue, but x3 is ok.  According to this analysis, the most fitted model is X5 but using Hamed's advice we would pick either X2 or X3 because he recommends that, to avoid overfitting, it is better to keep the model simple.  Choosing X2 would be choosing the simplest model, but would leave the improvements that the additional features obviously add to the accuracy of the predicted values.  Choosing X3 takes advantage of the additional accuracy.  Besides the \"keep it simple\" advice, the change in accuracy between the X2 model and the X3 model is greater than the change in accuracy between X3 and X4.  If there had been a more significant increase in accuracy, then it might have been better to choose X4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's consider more variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's first focus on correlation Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first get rid of additional variables we added to our dataframe\n",
    "del BostonData['lstat_2']\n",
    "del BostonData['lstat_3']\n",
    "del BostonData['lstat_4']\n",
    "del BostonData['lstat_5']\n",
    "BostonData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crim</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zn</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chas</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptratio</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstat</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medv</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim        zn     indus      chas       nox        rm       age  \\\n",
       "crim     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "zn      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "indus    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "chas    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "nox      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "rm      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "age      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "dis     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "rad      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "tax      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "ptratio  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "black   -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "lstat    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "medv    -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "              dis       rad       tax   ptratio     black     lstat      medv  \n",
       "crim    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
       "zn       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
       "indus   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
       "chas    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
       "nox     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
       "rm       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
       "age     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
       "dis      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
       "rad     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
       "tax     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
       "ptratio -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
       "black    0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
       "lstat   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
       "medv     0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "BostonData.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List 3 variables that have the highest chance to appear in your final model - the model that can predict medv. Can these variables appear simultaneously in your final model if your goal is interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: lstat (% lower economic status), ptratio (pupil teacher ratio), rm (number of rooms per dwelling) -- lstat and rm  have a strong negative correlation  (more than .3 is highly correlated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's standardize our data and put it in a new DataFrame called BostonDataNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>0.159686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.101524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>1.324247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>1.182758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>1.487503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim        zn     indus      chas       nox        rm       age  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        dis       rad       tax   ptratio     black     lstat      medv  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  0.159686  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.101524  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  1.324247  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  1.182758  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  1.487503  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonDataNew = preprocessing.scale(BostonData) #BostonDataNew is now a numpy array\n",
    "BostonDataNew = pd.DataFrame(BostonDataNew)   #We changed BostonDataNew to a dataframe\n",
    "BostonDataNew.columns = BostonData.columns.values  #We renamed columns of CreditDataNew\n",
    "BostonDataNew.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's use 10-fold cross validation and Lasso regression on our standardized data to decide which variables to eliminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crim' 'zn' 'indus' 'chas' 'nox' 'rm' 'age' 'dis' 'rad' 'tax' 'ptratio'\n",
      " 'black' 'lstat' 'medv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crim</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zn</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chas</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptratio</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstat</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medv</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim        zn     indus      chas       nox        rm       age  \\\n",
       "crim     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "zn      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "indus    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "chas    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "nox      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "rm      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "age      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "dis     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "rad      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "tax      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "ptratio  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "black   -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "lstat    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "medv    -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "              dis       rad       tax   ptratio     black     lstat      medv  \n",
       "crim    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
       "zn       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
       "indus   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
       "chas    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
       "nox     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
       "rm       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
       "age     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
       "dis      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
       "rad     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
       "tax     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
       "ptratio -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
       "black    0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
       "lstat   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
       "medv     0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfAllVariables = BostonDataNew.columns.values\n",
    "print listOfAllVariables\n",
    "X = BostonDataNew[listOfAllVariables]\n",
    "del X['medv']\n",
    "#del X['lstat_2']\n",
    "y = BostonDataNew['medv']\n",
    "BostonDataNew.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1e-10 0.284776127381\n",
      "Alpha: 1e-09 0.284776127081\n",
      "Alpha: 1e-08 0.284776124071\n",
      "Alpha: 1e-07 0.284776094077\n",
      "Alpha: 1e-06 0.284775793332\n",
      "Alpha: 1e-05 0.284772798881\n",
      "Alpha: 0.0001 0.284742148692\n",
      "Alpha: 0.001 0.284458912486\n",
      "Alpha: 0.01 0.287973732266\n",
      "Alpha: 0.1 0.346597594719\n",
      "Alpha: 1.0 1.00243049918\n",
      "Alpha: 10.0 1.00243049918\n",
      "Alpha: 100.0 1.00243049918\n",
      "Alpha: 1000.0 1.00243049918\n",
      "Alpha: 10000.0 1.00243049918\n",
      "Alpha: 100000.0 1.00243049918\n",
      "Alpha: 1000000.0 1.00243049918\n",
      "Alpha: 10000000.0 1.00243049918\n",
      "Alpha: 100000000.0 1.00243049918\n",
      "Alpha: 1000000000.0 1.00243049918\n",
      "Alpha: 10000000000.0 1.00243049918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1158d5790>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAELCAYAAAAiIMZEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4gESOEuIhIghbuISIAU7iIiAfr/A6hzBuFGgU8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1157ee0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = cross_validation.KFold(len(BostonDataNew), n_folds = 10, shuffle = True)\n",
    "MSE_Lasso_CV = []\n",
    "alphas = np.logspace(-10, 10, 21) #this is the lambda\n",
    "alphas_index = np.linspace(-10,10,21)\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    \n",
    "    scores = []\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.Lasso(alpha=a).fit(X.iloc[train_index], y.iloc[train_index])\n",
    "        scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(X.iloc[test_index])))\n",
    "    print 'Alpha:', a, np.mean(scores)\n",
    "    MSE_Lasso_CV.append(np.mean(scores))\n",
    "\n",
    "\n",
    "\n",
    "index = alphas\n",
    "MSE_Lasso_CV_df = pd.DataFrame({'MSE_Lasso_CV': MSE_Lasso_CV ,'Log_Alphas': alphas_index })\n",
    "MSE_Lasso_CV_df.plot(x = 'Log_Alphas',y = 'MSE_Lasso_CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.0, 'crim'), (0.0, 'zn'), (-0.0, 'indus'), (0.0073948593720603436, 'chas'), (-0.0, 'nox'), (0.30018561075517203, 'rm'), (-0.0, 'age'), (-0.0, 'dis'), (-0.0, 'rad'), (-0.0, 'tax'), (-0.15076235514591588, 'ptratio'), (0.026239609395646346, 'black'), (-0.38700973619760282, 'lstat')]\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.Lasso(alpha=10**(-1))\n",
    "lm.fit(X, y)\n",
    "print zip(lm.coef_,X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Choose rm or lstat due to high collinearity and also choose ptratio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's use 10-fold cross validation to choose our best model among the following candidates. Let's first add lstat**2 to our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BostonData['lstat_2'] = BostonData['lstat']**2\n",
    "X1 = BostonData[['lstat']]\n",
    "X2 = BostonData[['lstat','lstat_2']]\n",
    "X3 = BostonData[['lstat','chas']]\n",
    "X4 = BostonData[['lstat','lstat_2','chas']] #'black' is highly correlated with lstat so cannot consider them simoltanously\n",
    "X5 = BostonData[['ptratio','chas']]\n",
    "X6 = BostonData[['ptratio','chas','black']]\n",
    "X7 = BostonData[['ptratio','black']]\n",
    "X8 = BostonData[['rm']]\n",
    "X9 = BostonData[['rm','chas']]\n",
    "X10 = BostonData[['rm','chas','black']]\n",
    "X11 = BostonData[['rm','black']]\n",
    "X12 = BostonData[['lstat','ptratio','rm']]  #model without that much interpretability\n",
    "X13 = BostonData[['lstat','lstat_2','ptratio','rm']]  #model without that much interpretability\n",
    "X14 = BostonData[['lstat','ptratio','rm','chas','black']]  #model without that much interpretability\n",
    "X15 = BostonData[['lstat','lstat_2','ptratio','rm','chas','black']]  #model without that much interpretability\n",
    "y = BostonData['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_alpha</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10</td>\n",
       "      <td>38.943519</td>\n",
       "      <td>30.850695</td>\n",
       "      <td>37.563690</td>\n",
       "      <td>29.543467</td>\n",
       "      <td>62.690436</td>\n",
       "      <td>57.584382</td>\n",
       "      <td>57.993379</td>\n",
       "      <td>44.963780</td>\n",
       "      <td>44.252340</td>\n",
       "      <td>39.511537</td>\n",
       "      <td>40.154070</td>\n",
       "      <td>28.329386</td>\n",
       "      <td>24.107797</td>\n",
       "      <td>27.329114</td>\n",
       "      <td>23.103806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9</td>\n",
       "      <td>38.943519</td>\n",
       "      <td>30.850695</td>\n",
       "      <td>37.563690</td>\n",
       "      <td>29.543467</td>\n",
       "      <td>62.690436</td>\n",
       "      <td>57.584382</td>\n",
       "      <td>57.993379</td>\n",
       "      <td>44.963780</td>\n",
       "      <td>44.252340</td>\n",
       "      <td>39.511537</td>\n",
       "      <td>40.154070</td>\n",
       "      <td>28.329386</td>\n",
       "      <td>24.107797</td>\n",
       "      <td>27.329114</td>\n",
       "      <td>23.103806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8</td>\n",
       "      <td>38.943519</td>\n",
       "      <td>30.850695</td>\n",
       "      <td>37.563690</td>\n",
       "      <td>29.543467</td>\n",
       "      <td>62.690436</td>\n",
       "      <td>57.584382</td>\n",
       "      <td>57.993379</td>\n",
       "      <td>44.963780</td>\n",
       "      <td>44.252340</td>\n",
       "      <td>39.511537</td>\n",
       "      <td>40.154070</td>\n",
       "      <td>28.329386</td>\n",
       "      <td>24.107797</td>\n",
       "      <td>27.329114</td>\n",
       "      <td>23.103806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7</td>\n",
       "      <td>38.943519</td>\n",
       "      <td>30.850695</td>\n",
       "      <td>37.563690</td>\n",
       "      <td>29.543467</td>\n",
       "      <td>62.690436</td>\n",
       "      <td>57.584382</td>\n",
       "      <td>57.993379</td>\n",
       "      <td>44.963780</td>\n",
       "      <td>44.252340</td>\n",
       "      <td>39.511537</td>\n",
       "      <td>40.154070</td>\n",
       "      <td>28.329386</td>\n",
       "      <td>24.107797</td>\n",
       "      <td>27.329114</td>\n",
       "      <td>23.103806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6</td>\n",
       "      <td>38.943519</td>\n",
       "      <td>30.850695</td>\n",
       "      <td>37.563690</td>\n",
       "      <td>29.543467</td>\n",
       "      <td>62.690436</td>\n",
       "      <td>57.584382</td>\n",
       "      <td>57.993379</td>\n",
       "      <td>44.963780</td>\n",
       "      <td>44.252340</td>\n",
       "      <td>39.511537</td>\n",
       "      <td>40.154070</td>\n",
       "      <td>28.329386</td>\n",
       "      <td>24.107797</td>\n",
       "      <td>27.329113</td>\n",
       "      <td>23.103805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5</td>\n",
       "      <td>38.943519</td>\n",
       "      <td>30.850695</td>\n",
       "      <td>37.563689</td>\n",
       "      <td>29.543466</td>\n",
       "      <td>62.690433</td>\n",
       "      <td>57.584380</td>\n",
       "      <td>57.993378</td>\n",
       "      <td>44.963780</td>\n",
       "      <td>44.252339</td>\n",
       "      <td>39.511535</td>\n",
       "      <td>40.154072</td>\n",
       "      <td>28.329383</td>\n",
       "      <td>24.107795</td>\n",
       "      <td>27.329108</td>\n",
       "      <td>23.103801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4</td>\n",
       "      <td>38.943519</td>\n",
       "      <td>30.850689</td>\n",
       "      <td>37.563688</td>\n",
       "      <td>29.543458</td>\n",
       "      <td>62.690413</td>\n",
       "      <td>57.584361</td>\n",
       "      <td>57.993376</td>\n",
       "      <td>44.963779</td>\n",
       "      <td>44.252323</td>\n",
       "      <td>39.511511</td>\n",
       "      <td>40.154057</td>\n",
       "      <td>28.329364</td>\n",
       "      <td>24.107772</td>\n",
       "      <td>27.329060</td>\n",
       "      <td>23.103760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3</td>\n",
       "      <td>38.943517</td>\n",
       "      <td>30.850637</td>\n",
       "      <td>37.563690</td>\n",
       "      <td>29.543391</td>\n",
       "      <td>62.690229</td>\n",
       "      <td>57.584185</td>\n",
       "      <td>57.993383</td>\n",
       "      <td>44.963766</td>\n",
       "      <td>44.252183</td>\n",
       "      <td>39.511332</td>\n",
       "      <td>40.153910</td>\n",
       "      <td>28.329124</td>\n",
       "      <td>24.107546</td>\n",
       "      <td>27.328588</td>\n",
       "      <td>23.103368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2</td>\n",
       "      <td>38.943499</td>\n",
       "      <td>30.850135</td>\n",
       "      <td>37.565186</td>\n",
       "      <td>29.544217</td>\n",
       "      <td>62.689860</td>\n",
       "      <td>57.583921</td>\n",
       "      <td>57.993468</td>\n",
       "      <td>44.963819</td>\n",
       "      <td>44.252356</td>\n",
       "      <td>39.511023</td>\n",
       "      <td>40.152627</td>\n",
       "      <td>28.327302</td>\n",
       "      <td>24.105559</td>\n",
       "      <td>27.326105</td>\n",
       "      <td>23.101142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "      <td>38.943491</td>\n",
       "      <td>30.847745</td>\n",
       "      <td>37.727249</td>\n",
       "      <td>29.702176</td>\n",
       "      <td>62.833684</td>\n",
       "      <td>57.729364</td>\n",
       "      <td>57.996308</td>\n",
       "      <td>44.982588</td>\n",
       "      <td>44.411637</td>\n",
       "      <td>39.666628</td>\n",
       "      <td>40.158412</td>\n",
       "      <td>28.336252</td>\n",
       "      <td>24.113045</td>\n",
       "      <td>27.469858</td>\n",
       "      <td>23.248340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>38.961052</td>\n",
       "      <td>31.078920</td>\n",
       "      <td>38.961052</td>\n",
       "      <td>31.078920</td>\n",
       "      <td>63.348203</td>\n",
       "      <td>58.223888</td>\n",
       "      <td>58.223888</td>\n",
       "      <td>46.994200</td>\n",
       "      <td>46.994200</td>\n",
       "      <td>42.077592</td>\n",
       "      <td>42.077592</td>\n",
       "      <td>31.141948</td>\n",
       "      <td>26.939358</td>\n",
       "      <td>30.482468</td>\n",
       "      <td>26.401598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>40.900324</td>\n",
       "      <td>52.411356</td>\n",
       "      <td>40.900324</td>\n",
       "      <td>52.411356</td>\n",
       "      <td>84.350670</td>\n",
       "      <td>75.488756</td>\n",
       "      <td>75.488756</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>75.488756</td>\n",
       "      <td>75.488756</td>\n",
       "      <td>40.900324</td>\n",
       "      <td>52.411356</td>\n",
       "      <td>40.862118</td>\n",
       "      <td>51.291092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>52.551192</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>52.551192</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>76.841347</td>\n",
       "      <td>76.841347</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>76.841347</td>\n",
       "      <td>76.841347</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>52.551192</td>\n",
       "      <td>76.841347</td>\n",
       "      <td>52.471063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>70.266789</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>70.266789</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>70.266789</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>70.266789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "      <td>84.912336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    log_alpha          1          2          3          4          5  \\\n",
       "0         -10  38.943519  30.850695  37.563690  29.543467  62.690436   \n",
       "1          -9  38.943519  30.850695  37.563690  29.543467  62.690436   \n",
       "2          -8  38.943519  30.850695  37.563690  29.543467  62.690436   \n",
       "3          -7  38.943519  30.850695  37.563690  29.543467  62.690436   \n",
       "4          -6  38.943519  30.850695  37.563690  29.543467  62.690436   \n",
       "5          -5  38.943519  30.850695  37.563689  29.543466  62.690433   \n",
       "6          -4  38.943519  30.850689  37.563688  29.543458  62.690413   \n",
       "7          -3  38.943517  30.850637  37.563690  29.543391  62.690229   \n",
       "8          -2  38.943499  30.850135  37.565186  29.544217  62.689860   \n",
       "9          -1  38.943491  30.847745  37.727249  29.702176  62.833684   \n",
       "10          0  38.961052  31.078920  38.961052  31.078920  63.348203   \n",
       "11          1  40.900324  52.411356  40.900324  52.411356  84.350670   \n",
       "12          2  84.912336  52.551192  84.912336  52.551192  84.912336   \n",
       "13          3  84.912336  70.266789  84.912336  70.266789  84.912336   \n",
       "14          4  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "15          5  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "16          6  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "17          7  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "18          8  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "19          9  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "20         10  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "\n",
       "            6          7          8          9         10         11  \\\n",
       "0   57.584382  57.993379  44.963780  44.252340  39.511537  40.154070   \n",
       "1   57.584382  57.993379  44.963780  44.252340  39.511537  40.154070   \n",
       "2   57.584382  57.993379  44.963780  44.252340  39.511537  40.154070   \n",
       "3   57.584382  57.993379  44.963780  44.252340  39.511537  40.154070   \n",
       "4   57.584382  57.993379  44.963780  44.252340  39.511537  40.154070   \n",
       "5   57.584380  57.993378  44.963780  44.252339  39.511535  40.154072   \n",
       "6   57.584361  57.993376  44.963779  44.252323  39.511511  40.154057   \n",
       "7   57.584185  57.993383  44.963766  44.252183  39.511332  40.153910   \n",
       "8   57.583921  57.993468  44.963819  44.252356  39.511023  40.152627   \n",
       "9   57.729364  57.996308  44.982588  44.411637  39.666628  40.158412   \n",
       "10  58.223888  58.223888  46.994200  46.994200  42.077592  42.077592   \n",
       "11  75.488756  75.488756  84.912336  84.912336  75.488756  75.488756   \n",
       "12  76.841347  76.841347  84.912336  84.912336  76.841347  76.841347   \n",
       "13  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "14  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "15  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "16  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "17  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "18  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "19  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "20  84.912336  84.912336  84.912336  84.912336  84.912336  84.912336   \n",
       "\n",
       "           12         13         14         15  \n",
       "0   28.329386  24.107797  27.329114  23.103806  \n",
       "1   28.329386  24.107797  27.329114  23.103806  \n",
       "2   28.329386  24.107797  27.329114  23.103806  \n",
       "3   28.329386  24.107797  27.329114  23.103806  \n",
       "4   28.329386  24.107797  27.329113  23.103805  \n",
       "5   28.329383  24.107795  27.329108  23.103801  \n",
       "6   28.329364  24.107772  27.329060  23.103760  \n",
       "7   28.329124  24.107546  27.328588  23.103368  \n",
       "8   28.327302  24.105559  27.326105  23.101142  \n",
       "9   28.336252  24.113045  27.469858  23.248340  \n",
       "10  31.141948  26.939358  30.482468  26.401598  \n",
       "11  40.900324  52.411356  40.862118  51.291092  \n",
       "12  84.912336  52.551192  76.841347  52.471063  \n",
       "13  84.912336  70.266789  84.912336  70.266789  \n",
       "14  84.912336  84.912336  84.912336  84.912336  \n",
       "15  84.912336  84.912336  84.912336  84.912336  \n",
       "16  84.912336  84.912336  84.912336  84.912336  \n",
       "17  84.912336  84.912336  84.912336  84.912336  \n",
       "18  84.912336  84.912336  84.912336  84.912336  \n",
       "19  84.912336  84.912336  84.912336  84.912336  \n",
       "20  84.912336  84.912336  84.912336  84.912336  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = cross_validation.KFold(len(BostonDataNew), n_folds = 10, shuffle = True)\n",
    "MSE_alpha_CV = []\n",
    "alphas = np.logspace(-10, 10, 21) #this is the lambda\n",
    "alphas_index = np.linspace(-10,10,21)\n",
    "scores = []\n",
    "MSE_alpha_CV_df = pd.DataFrame({'log_alpha': alphas_index })\n",
    "\n",
    "\n",
    "MSE_CV = []\n",
    "j=0\n",
    "\n",
    "for i in [X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15]:\n",
    "    for a in alphas:\n",
    "        scores = []\n",
    "        for train_index, test_index in kf:\n",
    "            lm = linear_model.Lasso(alpha=a).fit(i.iloc[train_index], y.iloc[train_index])\n",
    "            scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(i.iloc[test_index])))\n",
    "        #print 'Alpha:', a, np.mean(scores)\n",
    "        MSE_CV.append(np.mean(scores))\n",
    "    j=j+1\n",
    "    MSE_alpha_CV_df[j] = MSE_CV\n",
    "    MSE_CV = []\n",
    "    \n",
    "MSE_alpha_CV_df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [(-0.94808448480347485, 'lstat')] 46.9676352359\n",
      "\n",
      "2 [(-2.306062811650615, 'lstat'), (0.042767546633610036, 'lstat_2')] 35.7078085105\n",
      "\n",
      "3 [(-0.9407138415358498, 'lstat'), (4.7645075485562529, 'chas')] 45.020066274\n",
      "\n",
      "4 [(-2.3128099296640889, 'lstat'), (0.043200611574037817, 'lstat_2'), (4.5954845913289102, 'chas')] 35.258174559\n",
      "\n",
      "5 [(-2.0977544395698824, 'ptratio'), (4.0180983544101876, 'chas')] 76.4641768491\n",
      "\n",
      "6 [(-1.914079383901647, 'ptratio'), (3.7694246158880995, 'chas'), (0.025028776673082582, 'black')] 75.8605906634\n",
      "\n",
      "7 [(-1.9656178848017449, 'ptratio'), (0.025323629719331463, 'black')] 75.4726735012\n",
      "\n",
      "8 [(9.0818124577463042, 'rm')] 54.6538330615\n",
      "\n",
      "9 [(8.9521374262004638, 'rm'), (3.9310912165277627, 'chas')] 53.9227940641\n",
      "\n",
      "10 [(8.5524883832883276, 'rm'), (3.5992804499034636, 'chas'), (0.024673693003422568, 'black')] 52.8752263285\n",
      "\n",
      "11 [(8.6649424934194812, 'rm'), (0.025051405866932854, 'black')] 53.1914932379\n",
      "\n",
      "12 [(-0.57352322767091468, 'lstat'), (-0.9299712840829113, 'ptratio'), (4.4852325691690922, 'rm')] 34.9766072138\n",
      "\n",
      "13 [(-1.6507767408240244, 'lstat'), (0.031996225646521666, 'lstat_2'), (-0.73021385292062657, 'ptratio'), (3.8458299091996073, 'rm')] 29.1829458053\n",
      "\n",
      "14 [(-0.51966508469341743, 'lstat'), (-0.8594697612329929, 'ptratio'), (4.6257983874422326, 'rm'), (3.1678416208776978, 'chas'), (0.010106505372557814, 'black')] 36.3063463063\n",
      "\n",
      "15 [(-1.5923631570621342, 'lstat'), (0.031650478403414777, 'lstat_2'), (-0.66346732558238553, 'ptratio'), (3.9621950150552148, 'rm'), (3.3336675926999537, 'chas'), (0.0088845483604509234, 'black')] 30.0446486703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j=1\n",
    "for i in [X1,X2]:\n",
    "    lm = linear_model.Lasso(alpha=10**(-1))\n",
    "    lm.fit(i, y)\n",
    "    print j, zip(lm.coef_,i.columns),metrics.mean_squared_error(y.iloc[test_index], lm.predict(i.iloc[test_index]))\n",
    "    j=j+1\n",
    "    print ''\n",
    "\n",
    "for i in [X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15]:\n",
    "    lm = linear_model.Lasso(alpha=10**(-2))\n",
    "    lm.fit(i, y)\n",
    "    print j, zip(lm.coef_,i.columns),metrics.mean_squared_error(y.iloc[test_index], lm.predict(i.iloc[test_index]))\n",
    "    j=j+1\n",
    "    print ''\n",
    "    \n",
    "# programming tasks:  how to get sorted list of mean square error with model number as index\n",
    "# how to create index with model name \"X1\" etc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If your goal is interpretation - what model(s) are you going to use? Use  smf.ols  in \"statsmodels.formula.api as smf\" to test significancy of your coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: don't understand what makes these more interpretable than the last set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.544\n",
      "Model:                            OLS   Adj. R-squared:                  0.543\n",
      "Method:                 Least Squares   F-statistic:                     601.6\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           5.08e-88\n",
      "Time:                        19:22:29   Log-Likelihood:                -1641.5\n",
      "No. Observations:                 506   AIC:                             3287.\n",
      "Df Residuals:                     504   BIC:                             3295.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     34.5538      0.563     61.415      0.000        33.448    35.659\n",
      "i             -0.9500      0.039    -24.528      0.000        -1.026    -0.874\n",
      "==============================================================================\n",
      "Omnibus:                      137.043   Durbin-Watson:                   0.892\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              291.373\n",
      "Skew:                           1.453   Prob(JB):                     5.36e-64\n",
      "Kurtosis:                       5.319   Cond. No.                         29.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.641\n",
      "Model:                            OLS   Adj. R-squared:                  0.639\n",
      "Method:                 Least Squares   F-statistic:                     448.5\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):          1.56e-112\n",
      "Time:                        19:22:29   Log-Likelihood:                -1581.3\n",
      "No. Observations:                 506   AIC:                             3169.\n",
      "Df Residuals:                     503   BIC:                             3181.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     42.8620      0.872     49.149      0.000        41.149    44.575\n",
      "i[0]          -2.3328      0.124    -18.843      0.000        -2.576    -2.090\n",
      "i[1]           0.0435      0.004     11.628      0.000         0.036     0.051\n",
      "==============================================================================\n",
      "Omnibus:                      107.006   Durbin-Watson:                   0.921\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              228.388\n",
      "Skew:                           1.128   Prob(JB):                     2.55e-50\n",
      "Kurtosis:                       5.397   Cond. No.                     1.13e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.13e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.563\n",
      "Model:                            OLS   Adj. R-squared:                  0.561\n",
      "Method:                 Least Squares   F-statistic:                     323.4\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           4.93e-91\n",
      "Time:                        19:22:29   Log-Likelihood:                -1631.1\n",
      "No. Observations:                 506   AIC:                             3268.\n",
      "Df Residuals:                     503   BIC:                             3281.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     34.0941      0.561     60.809      0.000        32.993    35.196\n",
      "i[0]          -0.9406      0.038    -24.729      0.000        -1.015    -0.866\n",
      "i[1]           4.9200      1.069      4.601      0.000         2.819     7.021\n",
      "==============================================================================\n",
      "Omnibus:                      131.896   Durbin-Watson:                   0.975\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              275.510\n",
      "Skew:                           1.406   Prob(JB):                     1.49e-60\n",
      "Kurtosis:                       5.272   Cond. No.                         57.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.658\n",
      "Model:                            OLS   Adj. R-squared:                  0.656\n",
      "Method:                 Least Squares   F-statistic:                     321.8\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):          1.75e-116\n",
      "Time:                        19:22:29   Log-Likelihood:                -1568.9\n",
      "No. Observations:                 506   AIC:                             3146.\n",
      "Df Residuals:                     502   BIC:                             3163.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     42.3651      0.858     49.400      0.000        40.680    44.050\n",
      "i[0]          -2.3149      0.121    -19.134      0.000        -2.553    -2.077\n",
      "i[1]           0.0433      0.004     11.826      0.000         0.036     0.050\n",
      "i[2]           4.7507      0.947      5.018      0.000         2.891     6.611\n",
      "==============================================================================\n",
      "Omnibus:                      104.929   Durbin-Watson:                   1.004\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              229.876\n",
      "Skew:                           1.095   Prob(JB):                     1.21e-50\n",
      "Kurtosis:                       5.471   Cond. No.                     1.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.271\n",
      "Model:                            OLS   Adj. R-squared:                  0.268\n",
      "Method:                 Least Squares   F-statistic:                     93.46\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           3.06e-35\n",
      "Time:                        19:22:29   Log-Likelihood:                -1760.3\n",
      "No. Observations:                 506   AIC:                             3527.\n",
      "Df Residuals:                     503   BIC:                             3539.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     60.9579      3.041     20.048      0.000        54.984    66.932\n",
      "i[0]          -2.0977      0.163    -12.874      0.000        -2.418    -1.778\n",
      "i[1]           4.1735      1.389      3.005      0.003         1.445     6.902\n",
      "==============================================================================\n",
      "Omnibus:                       77.406   Durbin-Watson:                   0.759\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              145.280\n",
      "Skew:                           0.883   Prob(JB):                     2.84e-32\n",
      "Kurtosis:                       4.942   Cond. No.                         162.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.331\n",
      "Model:                            OLS   Adj. R-squared:                  0.327\n",
      "Method:                 Least Squares   F-statistic:                     82.63\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           1.84e-43\n",
      "Time:                        19:22:29   Log-Likelihood:                -1738.7\n",
      "No. Observations:                 506   AIC:                             3485.\n",
      "Df Residuals:                     502   BIC:                             3502.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     48.6681      3.447     14.118      0.000        41.896    55.441\n",
      "i[0]          -1.9142      0.159    -12.063      0.000        -2.226    -1.602\n",
      "i[1]           3.9250      1.333      2.945      0.003         1.307     6.543\n",
      "i[2]           0.0250      0.004      6.688      0.000         0.018     0.032\n",
      "==============================================================================\n",
      "Omnibus:                       92.909   Durbin-Watson:                   0.795\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              191.950\n",
      "Skew:                           1.000   Prob(JB):                     2.08e-42\n",
      "Kurtosis:                       5.260   Cond. No.                     3.79e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.79e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.319\n",
      "Model:                            OLS   Adj. R-squared:                  0.316\n",
      "Method:                 Least Squares   F-statistic:                     117.8\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           1.08e-42\n",
      "Time:                        19:22:29   Log-Likelihood:                -1743.0\n",
      "No. Observations:                 506   AIC:                             3492.\n",
      "Df Residuals:                     503   BIC:                             3505.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     49.8204      3.451     14.437      0.000        43.040    56.600\n",
      "i[0]          -1.9678      0.159    -12.389      0.000        -2.280    -1.656\n",
      "i[1]           0.0253      0.004      6.721      0.000         0.018     0.033\n",
      "==============================================================================\n",
      "Omnibus:                      108.924   Durbin-Watson:                   0.762\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              249.419\n",
      "Skew:                           1.116   Prob(JB):                     6.91e-55\n",
      "Kurtosis:                       5.618   Cond. No.                     3.77e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.77e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.484\n",
      "Model:                            OLS   Adj. R-squared:                  0.483\n",
      "Method:                 Least Squares   F-statistic:                     471.8\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           2.49e-74\n",
      "Time:                        19:22:29   Log-Likelihood:                -1673.1\n",
      "No. Observations:                 506   AIC:                             3350.\n",
      "Df Residuals:                     504   BIC:                             3359.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -34.6706      2.650    -13.084      0.000       -39.877   -29.465\n",
      "i              9.1021      0.419     21.722      0.000         8.279     9.925\n",
      "==============================================================================\n",
      "Omnibus:                      102.585   Durbin-Watson:                   0.684\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              612.449\n",
      "Skew:                           0.726   Prob(JB):                    1.02e-133\n",
      "Kurtosis:                       8.190   Cond. No.                         58.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.496\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     247.6\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           1.36e-75\n",
      "Time:                        19:22:29   Log-Likelihood:                -1666.8\n",
      "No. Observations:                 506   AIC:                             3340.\n",
      "Df Residuals:                     503   BIC:                             3352.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -34.1067      2.625    -12.995      0.000       -39.263   -28.950\n",
      "i[0]           8.9674      0.416     21.555      0.000         8.150     9.785\n",
      "i[1]           4.0825      1.151      3.547      0.000         1.821     6.344\n",
      "==============================================================================\n",
      "Omnibus:                       92.470   Durbin-Watson:                   0.753\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              572.587\n",
      "Skew:                           0.619   Prob(JB):                    4.62e-125\n",
      "Kurtosis:                       8.062   Cond. No.                         58.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.555\n",
      "Model:                            OLS   Adj. R-squared:                  0.552\n",
      "Method:                 Least Squares   F-statistic:                     208.6\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           7.81e-88\n",
      "Time:                        19:22:29   Log-Likelihood:                -1635.5\n",
      "No. Observations:                 506   AIC:                             3279.\n",
      "Df Residuals:                     502   BIC:                             3296.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -40.3637      2.586    -15.607      0.000       -45.445   -35.282\n",
      "i[0]           8.5684      0.394     21.721      0.000         7.793     9.343\n",
      "i[1]           3.7512      1.084      3.462      0.001         1.622     5.880\n",
      "i[2]           0.0246      0.003      8.140      0.000         0.019     0.031\n",
      "==============================================================================\n",
      "Omnibus:                      145.855   Durbin-Watson:                   0.807\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              984.611\n",
      "Skew:                           1.073   Prob(JB):                    1.56e-214\n",
      "Kurtosis:                       9.488   Cond. No.                     3.52e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.52e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.544\n",
      "Model:                            OLS   Adj. R-squared:                  0.542\n",
      "Method:                 Least Squares   F-statistic:                     300.3\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):           1.47e-86\n",
      "Time:                        19:22:29   Log-Likelihood:                -1641.4\n",
      "No. Observations:                 506   AIC:                             3289.\n",
      "Df Residuals:                     503   BIC:                             3302.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -40.9811      2.608    -15.713      0.000       -46.105   -35.857\n",
      "i[0]           8.6856      0.397     21.862      0.000         7.905     9.466\n",
      "i[1]           0.0250      0.003      8.187      0.000         0.019     0.031\n",
      "==============================================================================\n",
      "Omnibus:                      158.364   Durbin-Watson:                   0.739\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1053.751\n",
      "Skew:                           1.190   Prob(JB):                    1.52e-229\n",
      "Kurtosis:                       9.657   Cond. No.                     3.51e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.51e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "for i in [X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11]:\n",
    "    lm1 = smf.ols(formula='y ~ i', data=BostonData).fit()\n",
    "    print(lm1.summary())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If your goal is prediction - what model(s) are you going to use? Use  smf.ols  in \"statsmodels.formula.api as smf\" to test significancy of your coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: model 1 : lstat, model 8 or 9: rm & chas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.679\n",
      "Model:                            OLS   Adj. R-squared:                  0.677\n",
      "Method:                 Least Squares   F-statistic:                     353.3\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):          2.69e-123\n",
      "Time:                        19:22:29   Log-Likelihood:                -1553.0\n",
      "No. Observations:                 506   AIC:                             3114.\n",
      "Df Residuals:                     502   BIC:                             3131.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     18.5671      3.913      4.745      0.000        10.879    26.255\n",
      "i[0]          -0.5718      0.042    -13.540      0.000        -0.655    -0.489\n",
      "i[1]          -0.9307      0.118     -7.911      0.000        -1.162    -0.700\n",
      "i[2]           4.5154      0.426     10.603      0.000         3.679     5.352\n",
      "==============================================================================\n",
      "Omnibus:                      202.072   Durbin-Watson:                   0.901\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1022.153\n",
      "Skew:                           1.700   Prob(JB):                    1.10e-222\n",
      "Kurtosis:                       9.076   Cond. No.                         402.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.727\n",
      "Model:                            OLS   Adj. R-squared:                  0.725\n",
      "Method:                 Least Squares   F-statistic:                     333.3\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):          1.19e-139\n",
      "Time:                        19:22:29   Log-Likelihood:                -1511.9\n",
      "No. Observations:                 506   AIC:                             3034.\n",
      "Df Residuals:                     501   BIC:                             3055.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     25.7849      3.692      6.984      0.000        18.532    33.038\n",
      "i[0]          -1.6499      0.121    -13.629      0.000        -1.888    -1.412\n",
      "i[1]           0.0320      0.003      9.406      0.000         0.025     0.039\n",
      "i[2]          -0.7308      0.111     -6.606      0.000        -0.948    -0.513\n",
      "i[3]           3.8754      0.399      9.717      0.000         3.092     4.659\n",
      "==============================================================================\n",
      "Omnibus:                      175.209   Durbin-Watson:                   0.897\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              884.420\n",
      "Skew:                           1.441   Prob(JB):                    8.93e-193\n",
      "Kurtosis:                       8.800   Cond. No.                     5.48e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.48e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.696\n",
      "Model:                            OLS   Adj. R-squared:                  0.693\n",
      "Method:                 Least Squares   F-statistic:                     228.9\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):          9.17e-127\n",
      "Time:                        19:22:29   Log-Likelihood:                -1539.0\n",
      "No. Observations:                 506   AIC:                             3090.\n",
      "Df Residuals:                     500   BIC:                             3115.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     11.8536      4.168      2.844      0.005         3.664    20.043\n",
      "i[0]          -0.5181      0.044    -11.792      0.000        -0.604    -0.432\n",
      "i[1]          -0.8583      0.115     -7.432      0.000        -1.085    -0.631\n",
      "i[2]           4.6523      0.420     11.076      0.000         3.827     5.478\n",
      "i[3]           3.3200      0.902      3.683      0.000         1.549     5.091\n",
      "i[4]           0.0101      0.003      3.743      0.000         0.005     0.015\n",
      "==============================================================================\n",
      "Omnibus:                      205.836   Durbin-Watson:                   0.978\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1116.216\n",
      "Skew:                           1.709   Prob(JB):                    4.14e-243\n",
      "Kurtosis:                       9.423   Cond. No.                     6.81e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.81e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.743\n",
      "Model:                            OLS   Adj. R-squared:                  0.740\n",
      "Method:                 Least Squares   F-statistic:                     240.5\n",
      "Date:                Mon, 22 Feb 2016   Prob (F-statistic):          9.64e-144\n",
      "Time:                        19:22:30   Log-Likelihood:                -1496.4\n",
      "No. Observations:                 506   AIC:                             3007.\n",
      "Df Residuals:                     499   BIC:                             3036.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     19.7377      3.923      5.031      0.000        12.030    27.446\n",
      "i[0]          -1.5920      0.119    -13.339      0.000        -1.826    -1.357\n",
      "i[1]           0.0317      0.003      9.564      0.000         0.025     0.038\n",
      "i[2]          -0.6621      0.108     -6.117      0.000        -0.875    -0.449\n",
      "i[3]           3.9877      0.393     10.154      0.000         3.216     4.759\n",
      "i[4]           3.4860      0.830      4.201      0.000         1.856     5.116\n",
      "i[5]           0.0089      0.002      3.571      0.000         0.004     0.014\n",
      "==============================================================================\n",
      "Omnibus:                      175.562   Durbin-Watson:                   0.977\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              958.482\n",
      "Skew:                           1.416   Prob(JB):                    7.38e-209\n",
      "Kurtosis:                       9.119   Cond. No.                     8.20e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.2e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "for i in [X12,X13,X14,X15]:\n",
    "    lm1 = smf.ols(formula='y ~ i', data=BostonDataNew).fit()\n",
    "    print(lm1.summary())\n",
    "    \n",
    "    #All of our models are highly significant, so we use model 15. It generates the least CV-MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
